\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{fullpage}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{titlesec}
\usepackage{caption}
\pagestyle{fancy}
\lhead{Justin Gomez, Paul Harmon}
\chead{Data Analysis Report}
\rhead{March 30, 2017}
\setlength{\headheight}{20pt}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.2pt}
\setlength{\parindent}{0pt}


\begin{document}



\begin{abstract}
College Basketball, including the NCAA Tournament, is growing in popularity and scope across the country. Winnng programs benefit from increased exposure, funding opportunities, and prestige. It is often of interest to try to predict which statistics are most strongly associated with winning a game. In order to analyze this, we fit binary regression models to analyze data from 49844 college basketball games since the 2003 season in order to determine which variables were most strongly associated with the probability of the home team winning. 

Results indicated that... 
\end{abstract

\section{Introduction}
\subsection{College Basketball: A Growing Sport}
NCAA College Basketball is a major cornerstone of college sports. While the games themselves have tremendous economic impact, college basketball's effects reach beyond the court. Broadcasting the tournament cost CBS nearly 10 billion dollars in 2016 (Ogus 2016). The effect on the schools’ academics is palpable, too; Smith (2008) notes that “a college’s profile will increase with big-time athletics, as will the perception of the school itself”. Indeed, some have even contended the increased visibility has impacts on academic metrics at those schools including increased student quality and retention. It is therefore of interest to not only coaches and fans but also campus administrators to determine which factors are most associated with winning basketball games. \\

\subsection{Predictive Analytics in NCAA Basketball}
Fans watching the NCAA Tournament are increasingly interested in making bets by filling out brackets, predicting each winner in the 7 rounds of the tournament; this has led to a proliferation of predictive modeling in College Basketball, both academic and casual. Some methods like those used by Harville and Smith (1992) make use of linear models to predict outcomes of games; however, more recent focus has been on so-called 'black box' predictive analytics.  While these are useful for simply predicting winners, these do not have much utility for inference; that is, they do not inform much about the factors that are most strongly associated with the probability of winning a game.  

This analysis is focused more on identifying metrics that are associated with the probabiliity of a team winning a game; therefore, we use generalized linear models to analzye the data. This analysis focuses mainly on the development of a binary regression model in order determine which factors may influence the probability of a home team winning a given game. The main questions of interest as are follows: 

\begin{enumerate}
\itemsep0em
\item %1
Which factors are most important in helping a home team win a game?

\item %2
Are winning teams more likely to win the turnover battle? 

\item %3
Do any of the variables measured modify the effect of other covariates of interest?

\end{enumerate}



Although the main goal of this analysis is to do statsitical inference, we do intend to test the predictive ability of our final model by generating predictions of wins and losses and comparing our predictions to a testing data set. 



\section{Data and Methods}

\subsection{The Data}
The data were obtained from a repository managed by Kaggle, Inc. related to the March Machine Learning Mania competition in 2016. We settled on a reduced set of fourteen predictor variables to include in our study of our single binary response: whether the home team won or not. Our dataset contains more than sixty-four thousand games spanning fourteen seasons of basketball. Since so much changes from year to year, including the season as a predictor may add useful information. Whether or not a game goes into overtime is also a variable of interest as it may provide some insight into the level of competition between the teams.To get an idea for how many points winning teams might need to put up in a typical game, we will also include the winning team's score. 

Our data consist of performance statistics for both teams summarized as either percentages or differentials. For percentage predictors, we have field goal, three-point, and free-throw percentages for both the winning and the losing teams. These are seperate variables for each team. All percentages were calculated as the number of made shots divided by the number of attempted shots. The differentials refer to the total count for the home team subtracted by the total count for the other team. We will be considering total rebounds (offensive rebounds plus defensive rebounds), assists, turnovers, steals, blocks, and personal fouls.  For instance, a positive rebound differential means that the winning team had more total rebounds than the losing team; a negative value would imply the opposite.  

Table 1 below lists the variables, each type, and the the manner in which they are calculated. 

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
Variable Name & Type & Nickname & How Calculated\\
\hline
Overtime& Binary & OT & 1 if game went to overtime, 0 else\\
\hline
Winning Field Goal Pct& PCT&WFGP & Shots Made/Shots Attempted\\
\hline
Losing Field Goal Pct& PCT&LFGP & Shots Made/Shots Attempted \\
\hline
Winning 3 Point Pct& PCT&W3P & 3 Pointers Made/3 Pointers Att\\
\hline
Losing 3 Point Pct& PCT&L3P & 3 Pointers Made/3 Pointers Att\\
\hline
Winning Free Throw Pct&PCT&WFTP & Free Throws Made/Free Throws Att\\
\hline
Losing Free Throw Pct& PCT&LFTP & Free Throws Made/Free Throws Att\\
\hline
Turnover Differential& DIFF&TDIFF & Winning Team TOs - Losing Team TOs\\
\hline
Assist Differential& DIFF&ASTDIFF & Winning Team Assits - Losing Team Assists\\
\hline
Steal Differential& DIFF &SDIFF & Winning Team Steals - Losing Team Steals\\
\hline
Block Differential& DIFF&BLKDIFF & Winning Team Block - Losing Team Block\\
\hline
Personal Foul Differential& DIFF&PFDIFF & Winning Team PF - Losing Team PF\\
\hline
Total Rebound Differential &DIFF&TRDIFF& Winning Team Rebounds - Losing Team Rebounds\\
\hline

\end{tabular}
\caption{}
\end{table}


\subsection{Generalized Linear Models}
The response in this analysis is binary; either the home team won the game and is assigned a value of "1" or the home team lost the game, in which case it is assigned a "0". Since our response variable follows a binomial distribution, we can perform logistic regression using the logit link function. In the context of our study, the logit is the log odds of the home team winning. The logit link is used as it is the canonical link function, which has properties that we like to take advantage of when fitting these models. Using this generalized linear model allows us to model the probability that the home team wins as function of our suite of predictor variables. Equation~\ref{eq:logit} is the general form of the model that we will be fitting.\\

\begin{equation} \label{eq:logit}
logit(\pi_{i})=log\Big(\frac{\pi_{i}}{1-\pi_{i}}\Big)=\sum_{j=1}^{p} \beta_{j}x_{ij}
\end{equation}

In this equation, $\pi_{i}$ is the probability that the home team wins, the $\beta_{j}$'s are the parameters that we are interested in estimating, and $x_{ij}$ is our observed data. Using the statistical software R, we can fit a logistic regression equation using the function \texttt{glm} in the \textt{stats} package. With this function, we can specify the predictor variables to be used, as well as the family the response follows and the link function to be used. As our data are ungrouped, conventional goodness-of-fit tests will not be accurate. Instead, we will use the Hosmer-Lemeshow goodness-of-fit test for binary data to assess our model fit. To perform this test, we fit our model to generate fitted probabilities. Then, we order these probabilities and group them by quantiles. Ten groups is a common choice and so we will be grouping our fitted probabilities into ten groups. From there, the observed and expected number of success are found in each group and compared. Generally speaking, if these values are close, we do not have evidence that our specified model does not fit well, but if there are large differences, there is evidence that our model is not a good fit for the data.\\

\subsection{Link Functions}

\section{Results}


\section{Discussion}
\subsection{Logistic Regression}
The results on 

\subsection{}



\section{Appendix}

<<freakingdataanalysis, include = FALSE>>=
#model

@





\end{document}